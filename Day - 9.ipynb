{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to PDF Data Extraction:\n",
    "- Understanding the structure of PDFs\n",
    "- Overview of Python libraries for PDF extraction (PyPDF2, pdfplumber,tabula-py)\n",
    "\n",
    "- Hands-on Activities: \n",
    "    - Identifying the structure of different PDFs\n",
    "    - Setting up the Python environment for PDF data extraction\n",
    "\n",
    "**1. Understanding PDF Structures**\n",
    "\n",
    "PDF files can have different internal structures:\n",
    "\n",
    "| PDF Type        | Characteristics                                        | Example Use                      |\n",
    "| --------------- | ------------------------------------------------------ | -------------------------------- |\n",
    "| **Text-based**  | Contains actual digital text (selectable & searchable) | Bank statements, invoices        |\n",
    "| **Image-based** | Scanned images or photos                               | Handwritten notes, scanned forms |\n",
    "| **Mixed PDFs**  | Contains both text and scanned images                  | Annotated or signed documents    |\n",
    "\n",
    "Understanding the structure is crucial before deciding which tool to use (e.g., `PyMuPDF`, `pdfplumber`, `Tesseract`).\n",
    "\n",
    "**2. Setting Up Python Environment**\n",
    "\n",
    "To extract data, you'll need the right libraries installed. Use this command to set them up:\n",
    "\n",
    "```bash\n",
    "pip install pdfplumber pytesseract PyMuPDF opencv-python pillow\n",
    "```\n",
    "\n",
    "Also install **Tesseract-OCR** (needed for image-based PDFs):\n",
    "\n",
    "* Windows: [Download installer](https://github.com/tesseract-ocr/tesseract)\n",
    "\n",
    "**3. Python Tools & When to Use**\n",
    "\n",
    "| Tool                   | Best for                                         | Usage                              |\n",
    "| ---------------------- | ------------------------------------------------ | ---------------------------------- |\n",
    "| `pdfplumber`           | Extracting text, tables from **text-based PDFs** | High accuracy for structured text  |\n",
    "| `PyMuPDF` (fitz)       | Text & layout data; images                       | Versatile for both text and layout |\n",
    "| `pytesseract + OpenCV` | **OCR on image-based PDFs**                      | Converts images to text            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pdfplumber`\n",
    "**`pdfplumber`** is a Python library for **extracting text, tables, and metadata** from PDF files. Unlike basic text extractors, `pdfplumber` gives **fine-grained access** to PDF layout elements such as individual characters, lines, words, and table structuresâ€”making it ideal for **structured data extraction**, especially from PDFs exported from spreadsheets or forms.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* Extract full text or individual words with coordinates\n",
    "* Extract structured tables from PDFs\n",
    "* Access layout metadata (bounding boxes, fonts)\n",
    "* Crop and visually render pages for inspection\n",
    "* Great for working with PDFs generated from Excel, scans, and forms\n",
    "\n",
    "Install it with:\n",
    "\n",
    "```bash\n",
    "pip install pdfplumber\n",
    "```\n",
    "\n",
    "<table style=\"width: 80%; border-collapse: collapse; border: 1px solid #ccc; text-align: left;margin-left: 0;\">\n",
    "  <thead>\n",
    "    <tr style=\"background-color: #050A30; color: white;\">\n",
    "      <th>Function / Class</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><code>pdfplumber.open(path)</code></td>\n",
    "      <td>Opens the PDF file at the given path and returns a <code>PDF</code> object.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>pdf.pages</code></td>\n",
    "      <td>A list of <code>Page</code> objects, one for each page in the PDF.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>page.extract_text()</code></td>\n",
    "      <td>Extracts all text from the page as a string.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>page.extract_words()</code></td>\n",
    "      <td>Extracts a list of words with coordinates, useful for detailed parsing.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>page.extract_table()</code></td>\n",
    "      <td>Extracts a single table (if found) from the page as a list of lists.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>page.extract_tables()</code></td>\n",
    "      <td>Extracts all tables from the page, each as a list of lists.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>pdf.pages[i]</code></td>\n",
    "      <td>Accesses the <i>i-th</i> page of the PDF as a <code>Page</code> object.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\vaide\\OneDrive - knowledgecorner.in\\Course Material\\Clients\\Virtua Search\\Vituare-Research\\Datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ex. For more structured table in PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(r\"data_pdf_1.pdf\")\n",
    "for page in pdf.pages :\n",
    "    print(page.extract_table(), \"\\n -------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for page in pdf.pages :\n",
    "    df = pd.concat((df, pd.DataFrame(page.extract_table())), ignore_index=True)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(index = 0).reset_index(drop= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ex. Reading data from pdf with table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(r\"data_pdf_2.pdf\")\n",
    "for page in pdf.pages :\n",
    "    print(page.extract_text(), \"\\n -------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using basic list and str handling\n",
    "pdf = pdfplumber.open(r\"data_pdf_2.pdf\")\n",
    "lines = []\n",
    "for page in pdf.pages :\n",
    "    lines.extend(page.extract_text().split(\"\\n\"))\n",
    "header = lines[0].split()\n",
    "data = [line for line in lines[1:] if re.match(r\"\\d{5}\", line.strip())]\n",
    "\n",
    "def clean_data(string) :\n",
    "    parts = string.split()\n",
    "    return [parts[0], \" \".join(parts[1:4]), parts[4], \" \".join(parts[5:7]), *parts[7:]]\n",
    "\n",
    "df1 = pd.DataFrame(map(clean_data, data), columns = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regular expression\n",
    "pdf = pdfplumber.open(r\"data_pdf_2.pdf\")\n",
    "lines = []\n",
    "for page in pdf.pages :\n",
    "    lines.extend(page.extract_text().split(\"\\n\"))\n",
    "header = lines[0].split()\n",
    "data = [line for line in lines[1:] if re.match(r\"\\d{5}\", line.strip())]\n",
    "\n",
    "def clean_data(string) :\n",
    "    pattern = r'^(\\d+)\\s+(.+?)\\s+([A-Za-z]+)\\s+(Q\\d\\s+\\d{2}|FY\\s+\\d{2})\\s+(\\d{2}-\\d{2}-\\d{4})\\s+(\\d{2}-\\d{2}-\\d{4})\\s+(\\d{2}-\\d{2}-\\d{4})$'\n",
    "    result = re.match(pattern, string)\n",
    "    return result.groups() if result else [np.nan] * 7\n",
    "\n",
    "df1 = pd.DataFrame(map(clean_data, data), columns = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.equals(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ex. Image to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using pytesseract\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "# Path to Tesseract executable (adjust this)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "text = image_to_string(\"data.png\", lang=\"eng\", config = r'--oem 3 --psm 6')\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "header = lines[0].split()\n",
    "data = [line for line in lines[1:] if re.match(r\"\\d{5}\", line.strip())]\n",
    "\n",
    "def clean_data(string) :\n",
    "    pattern = r'^(\\d+)\\s+(.+?)\\s+([A-Za-z]+)\\s+(Q\\d\\d{2}|FY\\s+\\d{2})\\s+(\\d{2}-\\d{2}-\\d{4})\\s+(\\d{2}-\\d{2}-\\d{4})\\s+(\\d{2}-\\d{2}-\\d{4})$'\n",
    "    result = re.match(pattern, string)\n",
    "    return result.groups() if result else [np.nan] * 7\n",
    "\n",
    "df2 = pd.DataFrame(map(clean_data, data), columns = header).dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"PeriodName\"]).iloc[:22].equals(df2.drop(columns=[\"PeriodName\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyocr import Reader\n",
    "\n",
    "reader = Reader(['en'])\n",
    "text = reader.readtext(\"data.png\", detail=0)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(text[3:], np.ones(5))\n",
    "df = pd.DataFrame(np.reshape(data, (24, 6)), columns=['A', 'Ticker',  \"PeriodName\", \"PeriodEndDate\", \"FirstFillingDate\", \"LatestFillingDate\"])\n",
    "df = df.iloc[:-2]\n",
    "df.loc[len(df)] = ['10688 Meta Platforms, Inc.', 'META', '03 11', '30-09-2011', '15-10-2011', '15-10-201']\n",
    "df[['COID', 'CoName']] = df[\"A\"].str.split(r\"\\d \", expand= True, regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Keras-OCR\n",
    "# pip install tensorflow\n",
    "# pip install keras-ocr \n",
    "'''\n",
    "Check Compatible NumPy Version for TensorFlow\n",
    "\n",
    "TensorFlow Version\tCompatible NumPy Versions\n",
    "TF 2.15+    \tNumPy â‰¥ 1.20.0, â‰¤ 1.26\n",
    "TF 2.11â€“2.14  \tNumPy â‰¥ 1.20.0, â‰¤ 1.24\n",
    "TF 2.10\t        NumPy â‰¥ 1.20.0, â‰¤ 1.23\n",
    "TF 2.6â€“2.9\t    NumPy â‰¥ 1.19.0, â‰¤ 1.22\n",
    "\n",
    "keras-ocr uses TensorFlow under the hood. So match NumPy accordingly.\n",
    "\n",
    "pip install numpy==1.23.5\n",
    "pip install tensorflow==2.10.0\n",
    "pip install keras==2.10.0\n",
    "pip install keras-ocr\n",
    "\n",
    "'''\n",
    "\n",
    "import keras_ocr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "\n",
    "# Read image\n",
    "image = keras_ocr.tools.read(\"data2.png\")\n",
    "prediction_groups = pipeline.recognize([image])\n",
    "\n",
    "\n",
    "# Extract text only\n",
    "text = [word for word, box in prediction_groups[0]]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanned PDF to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=3300x2550>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "pdf_path = \"data_pdf_4.pdf\"\n",
    "images = convert_from_path(pdf_path, dpi = 300)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "print(pytesseract.image_to_string(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "from easyocr import Reader\n",
    "reader = Reader([\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaide\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COID', 'CoName', 'Ticker PeriodName', 'PeriodEndDate FirstFillingDate LatestFillingDate', '10688 Meta Platforms, Inc:', 'META', 'Q1 07', '31-03-2007', '15-04-2007', '15-04-2007', '10688 Meta Platforms, Inc:', 'META', 'Q2 07', '30-06-2007', '15-07-2007', '15-07-2007', '10688 Meta Platforms, Inc:', 'META', 'Q3 07', '30-09-2007', '15-10-2007', '15-10-2007', '10688 Meta Platforms, Inc:', 'META', 'Q4 07', '31-12-2007', '15-01-2008', '15-01-2008', '10688 Meta Platforms, Inc:', 'META', 'FY 07', '31-12-2007', '15-01-2008', '15-01-2008', '10688 Meta Platforms, Inc:', 'META', 'Q1 08', '31-03-2008', '15-04-2008', '15-04-2008', '10688 Meta Platforms, Inc.', 'META', 'Q2 08', '30-06-2008', '15-07-2008', '15-07-2008', '10688 Meta Platforms, Inc', 'META', 'Q3 08', '30-09-2008', '15-10-2008', '15-10-2008', '10688 Meta Platforms, Inc:', 'META', 'Q4 08', '31-12-2008', '15-01-2009', '15-01-2009', '10688 Meta Platforms, Inc:', 'META', 'FY 08', '31-12-2008', '15-01-2009', '15-01-2009', '10688 Meta Platforms, Inc.', 'META', 'Q1 09', '31-03-2009', '15-04-2009', '15-04-2009', '10688 Meta Platforms, Inc:', 'META', 'Q2 09', '30-06-2009', '15-07-2009', '15-07-2009', '10688 Meta Platforms, Inc:', 'META', 'Q3 09', '30-09-2009', '15-10-2009', '15-10-2009', '10688 Meta Platforms, Inc:', 'META', 'Q4 09', '31-12-2009', '15-01-2010', '15-01-2010', '10688 Meta Platforms, Inc:', 'META', 'FY 09', '31-12-2009', '15-01-2010', '15-01-2010', '10688 Meta Platforms, Inc.', 'META', 'Q1 10', '31-03-2010', '15-04-2010', '15-04-2010', '10688 Meta Platforms, Inc.', 'META', 'Q2 10', '30-06-2010', '15-07-2010', '15-07-2010', '10688 Meta Platforms, Inc.', 'META', 'Q3 10', '30-09-2010', '15-10-2010', '15-10-2010', '10688 Meta Platforms, Inc:', 'META', 'Q4 10', '31-12-2010', '15-01-2011', '15-01-2011', '10688 Meta Platforms, Inc:', 'META', 'FY 10', '31-12-2010', '15-01-2011', '01-02-2013', '10688 Meta Platforms, Inc.', 'META', 'Q1 11', '31-03-2011', '15-04-2011', '15-04-2011', '10688 Meta Platforms, Inc_', 'META', 'Q2 11', '30-06-2011', '15-07-2011', '15-07-2011', '10688 Meta Platforms, Inc.', 'META', 'Q3 11', '30-09-2011', '15-10-2011', '15-10-2011']\n"
     ]
    }
   ],
   "source": [
    "images[0].save(\"temp.png\", \"PNG\")\n",
    "print(reader.readtext(\"temp.png\", detail=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
